{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a7d6ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "%matplotlib inline\n",
    "InteractiveShell.ast_node_interactivity='all'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746065e3",
   "metadata": {},
   "source": [
    "# Preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8371d1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6aca2290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training data into features and labels\n",
    "x_train = train_file.loc[:, train_file.columns!='label']\n",
    "y_train = train_file.loc[:, train_file.columns=='label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce533bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and validation set\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(x_train, y_train, test_size=0.1, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32f6e220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert from df to np array\n",
    "X_train = X_train.to_numpy()\n",
    "X_valid = X_valid.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fb571f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for dataloader\n",
    "transform = transforms.Compose([transforms.Resize([32,32])])\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.X = x.reshape(x.shape[0], 1, 28, 28)\n",
    "        self.X = self.X / 255\n",
    "        self.X = torch.from_numpy(self.X.astype(np.float32))\n",
    "        self.X = transform(self.X)\n",
    "        \n",
    "        y.resize(y.shape[0],)\n",
    "        self.Y = torch.from_numpy(y).type(torch.LongTensor)\n",
    "        \n",
    "        self.len = self.X.shape[0]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index]\n",
    "   \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cbebda91",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = Data(X_train, Y_train)\n",
    "valid = Data(X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7fc07c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "trainloader = DataLoader(train, batch_size = batch_size, shuffle = True)\n",
    "validloader = DataLoader(valid, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afc47ac",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67e25523",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=0)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0)\n",
    "        self.fc = nn.Linear(in_features=400, out_features=120)\n",
    "        self.fc1 = nn.Linear(in_features=120, out_features=84)\n",
    "        self.fc2 = nn.Linear(in_features=84, out_features=10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.pool(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.pool(out)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        out = self.fc(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072e5c0d",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "85075517",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = LeNet5()\n",
    "cost = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "73e407ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss:0.6255, accuracy: 80.9127%\n",
      "epoch: 2, loss:0.2001, accuracy: 93.9259%\n",
      "epoch: 3, loss:0.1240, accuracy: 96.1958%\n",
      "epoch: 4, loss:0.0943, accuracy: 97.1508%\n",
      "epoch: 5, loss:0.0762, accuracy: 97.6243%\n",
      "epoch: 6, loss:0.0637, accuracy: 97.9630%\n",
      "epoch: 7, loss:0.0550, accuracy: 98.2778%\n",
      "epoch: 8, loss:0.0490, accuracy: 98.4127%\n",
      "epoch: 9, loss:0.0422, accuracy: 98.6772%\n",
      "epoch: 10, loss:0.0395, accuracy: 98.7884%\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch_train = len(trainloader)\n",
    "epochs = 10\n",
    "\n",
    "accuracy_list = []\n",
    "loss_list = []\n",
    "\n",
    "# iterate through each epoch\n",
    "for epoch in range(epochs):\n",
    "    current_loss = 0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for features, labels in trainloader:\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(features)\n",
    "        loss = cost(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        current_loss += loss.item()\n",
    "        predicted = outputs.argmax(axis=1).numpy()\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.numpy()).sum().item()\n",
    "        \n",
    "    loss_list.append(current_loss/steps_per_epoch)\n",
    "    accuracy_list.append(100*correct/total)\n",
    "    \n",
    "    print(f'epoch: {epoch+1}, loss:{current_loss/steps_per_epoch:.4f}, accuracy: {100*correct/total:.4f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b91592",
   "metadata": {},
   "source": [
    "# Predict on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ed6662d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.3095%\n"
     ]
    }
   ],
   "source": [
    "pred_list = []\n",
    "total=0\n",
    "correct=0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for features, labels in validloader:\n",
    "        outputs = model(features)\n",
    "        \n",
    "        predicted = outputs.argmax(axis=1).numpy()\n",
    "        pred_list.append(predicted)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.numpy()).sum().item()\n",
    "\n",
    "print(f'Accuracy: {100 * correct / total:.4f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1ce5ff",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "275987ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b05398db",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['fake_labels'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8fb84723",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Data(test_data.loc[:, test_data.columns!='fake_labels'].to_numpy(), test_data.fake_labels.to_numpy())\n",
    "testloader = DataLoader(test, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c1e68dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = torch.LongTensor()\n",
    "with torch.no_grad():\n",
    "    for features, targets in testloader:\n",
    "        outputs = model(features)\n",
    "        predictions = outputs.argmax(axis=1)\n",
    "        submission = torch.cat((submission, predictions), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "276cbcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(submission.numpy(), columns=['Label'])\n",
    "submission_df.index = [i for i in range(1,len(submission_df)+1)]\n",
    "submission_df.index.name = 'ImageId'\n",
    "submission_df.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e84f21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
